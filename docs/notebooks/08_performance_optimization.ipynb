{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Performance Optimization: Profiling and Benchmarking\n\nThis notebook covers performance optimization techniques for tracking applications. We explore:\n\n1. **Profiling Basics** - Identifying bottlenecks\n2. **Numba JIT Compilation** - Accelerating numerical code\n3. **Vectorization** - Efficient NumPy operations\n4. **Caching Strategies** - Avoiding redundant computations\n5. **Memory Optimization** - Reducing allocations\n6. **Benchmarking Best Practices** - Reliable measurements\n\n## Prerequisites\n\n```bash\npip install nrl-tracker plotly numpy numba line_profiler memory_profiler\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport time\nimport cProfile\nimport pstats\nfrom io import StringIO\nfrom functools import lru_cache\n\ntry:\n    from numba import njit, prange\n    NUMBA_AVAILABLE = True\nexcept ImportError:\n    NUMBA_AVAILABLE = False\n    print(\"Numba not available. Install with: pip install numba\")\n\n# Import tracking functions\nfrom pytcl.dynamic_estimation.kalman import kf_predict, kf_update\nfrom pytcl.assignment_algorithms import hungarian_assignment\nfrom pytcl.dynamic_estimation.particle_filters import (\n    resample_systematic, effective_sample_size\n)\n\nnp.random.seed(42)\n\n# Plotly dark theme template\ndark_template = go.layout.Template()\ndark_template.layout = go.Layout(\n    paper_bgcolor='#0d1117',\n    plot_bgcolor='#0d1117',\n    font=dict(color='#e6edf3'),\n    xaxis=dict(gridcolor='#30363d', zerolinecolor='#30363d'),\n    yaxis=dict(gridcolor='#30363d', zerolinecolor='#30363d'),\n)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Profiling Basics\n",
    "\n",
    "Before optimizing, identify where time is actually spent.\n",
    "\n",
    "### Profiling Tools\n",
    "\n",
    "| Tool | Purpose | Overhead |\n",
    "|------|---------|----------|\n",
    "| `time.time()` | Quick timing | Minimal |\n",
    "| `cProfile` | Function-level profiling | Moderate |\n",
    "| `line_profiler` | Line-by-line profiling | High |\n",
    "| `memory_profiler` | Memory usage | High |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_timer(func, *args, n_runs=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Time a function call with multiple runs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Function to time.\n",
    "    *args : tuple\n",
    "        Arguments to pass to function.\n",
    "    n_runs : int\n",
    "        Number of timing runs.\n",
    "    **kwargs : dict\n",
    "        Keyword arguments to pass to function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Timing statistics.\n",
    "    \"\"\"\n",
    "    # Warmup\n",
    "    func(*args, **kwargs)\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "        'n_runs': n_runs\n",
    "    }\n",
    "\n",
    "# Example: Time matrix multiplication\n",
    "n = 500\n",
    "A = np.random.randn(n, n)\n",
    "B = np.random.randn(n, n)\n",
    "\n",
    "stats = simple_timer(np.dot, A, B, n_runs=20)\n",
    "print(f\"Matrix multiplication ({n}x{n}):\")\n",
    "print(f\"  Mean: {stats['mean']*1e3:.2f} ms\")\n",
    "print(f\"  Std:  {stats['std']*1e3:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile a tracking scenario\n",
    "def run_kalman_tracking(n_steps=100):\n",
    "    \"\"\"Run Kalman filter tracking.\"\"\"\n",
    "    # System matrices\n",
    "    dt = 1.0\n",
    "    F = np.array([[1, dt, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, dt],\n",
    "                  [0, 0, 0, 1]])\n",
    "    H = np.array([[1, 0, 0, 0],\n",
    "                  [0, 0, 1, 0]])\n",
    "    Q = np.eye(4) * 0.1\n",
    "    R = np.eye(2) * 1.0\n",
    "    \n",
    "    x = np.zeros(4)\n",
    "    P = np.eye(4) * 100\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        # Predict\n",
    "        x = F @ x\n",
    "        P = F @ P @ F.T + Q\n",
    "        \n",
    "        # Update\n",
    "        z = np.random.randn(2) * np.sqrt(R[0, 0])\n",
    "        y = z - H @ x\n",
    "        S = H @ P @ H.T + R\n",
    "        K = P @ H.T @ np.linalg.inv(S)\n",
    "        x = x + K @ y\n",
    "        P = (np.eye(4) - K @ H) @ P\n",
    "    \n",
    "    return x, P\n",
    "\n",
    "# Profile with cProfile\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for _ in range(100):\n",
    "    run_kalman_tracking(100)\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Print top 10 functions by cumulative time\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "ps.print_stats(10)\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Numba JIT Compilation\n",
    "\n",
    "Numba compiles Python functions to optimized machine code at runtime.\n",
    "\n",
    "### Key Features\n",
    "- `@njit` - Compile without Python interpreter (\"nopython\" mode)\n",
    "- `@njit(parallel=True)` - Automatic parallelization\n",
    "- `prange` - Parallel range for loops\n",
    "- `cache=True` - Cache compiled code between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Python implementation\n",
    "def compute_distances_python(points, center):\n",
    "    \"\"\"Compute distances from points to center (pure Python).\"\"\"\n",
    "    n = len(points)\n",
    "    distances = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        d = 0.0\n",
    "        for j in range(len(center)):\n",
    "            d += (points[i, j] - center[j]) ** 2\n",
    "        distances[i] = np.sqrt(d)\n",
    "    return distances\n",
    "\n",
    "# Vectorized NumPy implementation\n",
    "def compute_distances_numpy(points, center):\n",
    "    \"\"\"Compute distances from points to center (NumPy).\"\"\"\n",
    "    return np.sqrt(np.sum((points - center) ** 2, axis=1))\n",
    "\n",
    "if NUMBA_AVAILABLE:\n",
    "    # Numba JIT implementation\n",
    "    @njit(cache=True)\n",
    "    def compute_distances_numba(points, center):\n",
    "        \"\"\"Compute distances from points to center (Numba).\"\"\"\n",
    "        n = len(points)\n",
    "        dim = len(center)\n",
    "        distances = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            d = 0.0\n",
    "            for j in range(dim):\n",
    "                d += (points[i, j] - center[j]) ** 2\n",
    "            distances[i] = np.sqrt(d)\n",
    "        return distances\n",
    "\n",
    "    # Parallel Numba implementation\n",
    "    @njit(parallel=True, cache=True)\n",
    "    def compute_distances_numba_parallel(points, center):\n",
    "        \"\"\"Compute distances from points to center (parallel Numba).\"\"\"\n",
    "        n = len(points)\n",
    "        dim = len(center)\n",
    "        distances = np.zeros(n)\n",
    "        for i in prange(n):\n",
    "            d = 0.0\n",
    "            for j in range(dim):\n",
    "                d += (points[i, j] - center[j]) ** 2\n",
    "            distances[i] = np.sqrt(d)\n",
    "        return distances\n",
    "\n",
    "print(\"Distance functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark different implementations\n",
    "n_points_list = [1000, 10000, 100000, 1000000]\n",
    "dim = 3\n",
    "\n",
    "python_times = []\n",
    "numpy_times = []\n",
    "numba_times = []\n",
    "numba_parallel_times = []\n",
    "\n",
    "for n_points in n_points_list:\n",
    "    points = np.random.randn(n_points, dim)\n",
    "    center = np.random.randn(dim)\n",
    "    \n",
    "    # Python (only for smaller sizes)\n",
    "    if n_points <= 10000:\n",
    "        stats = simple_timer(compute_distances_python, points, center, n_runs=3)\n",
    "        python_times.append(stats['mean'])\n",
    "    else:\n",
    "        python_times.append(np.nan)\n",
    "    \n",
    "    # NumPy\n",
    "    stats = simple_timer(compute_distances_numpy, points, center, n_runs=10)\n",
    "    numpy_times.append(stats['mean'])\n",
    "    \n",
    "    if NUMBA_AVAILABLE:\n",
    "        # Numba (warmup first)\n",
    "        _ = compute_distances_numba(points, center)\n",
    "        stats = simple_timer(compute_distances_numba, points, center, n_runs=10)\n",
    "        numba_times.append(stats['mean'])\n",
    "        \n",
    "        # Parallel Numba\n",
    "        _ = compute_distances_numba_parallel(points, center)\n",
    "        stats = simple_timer(compute_distances_numba_parallel, points, center, n_runs=10)\n",
    "        numba_parallel_times.append(stats['mean'])\n",
    "    \n",
    "    print(f\"n={n_points:7d}: NumPy={numpy_times[-1]*1e3:7.2f}ms\", end='')\n",
    "    if NUMBA_AVAILABLE:\n",
    "        print(f\", Numba={numba_times[-1]*1e3:7.2f}ms, \"\n",
    "              f\"Parallel={numba_parallel_times[-1]*1e3:7.2f}ms\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize performance comparison\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(x=n_points_list, y=np.array(numpy_times)*1e3, mode='lines+markers',\n               name='NumPy', line=dict(color='#00d4ff', width=2),\n               marker=dict(size=8))\n)\nif NUMBA_AVAILABLE:\n    fig.add_trace(\n        go.Scatter(x=n_points_list, y=np.array(numba_times)*1e3, mode='lines+markers',\n                   name='Numba', line=dict(color='#00ff88', width=2),\n                   marker=dict(size=8, symbol='square'))\n    )\n    fig.add_trace(\n        go.Scatter(x=n_points_list, y=np.array(numba_parallel_times)*1e3, mode='lines+markers',\n                   name='Numba Parallel', line=dict(color='#ff4757', width=2),\n                   marker=dict(size=8, symbol='triangle-up'))\n    )\n\nfig.update_layout(\n    template=dark_template,\n    title='Distance Computation Performance',\n    xaxis_title='Number of Points',\n    yaxis_title='Time (ms)',\n    xaxis_type='log',\n    yaxis_type='log',\n    height=450,\n)\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Vectorization Patterns\n",
    "\n",
    "Replacing loops with vectorized NumPy operations can provide significant speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compute pairwise distances\n",
    "\n",
    "def pairwise_distances_loop(X):\n",
    "    \"\"\"Compute pairwise distances using loops.\"\"\"\n",
    "    n = len(X)\n",
    "    D = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d = np.sqrt(np.sum((X[i] - X[j])**2))\n",
    "            D[i, j] = d\n",
    "            D[j, i] = d\n",
    "    return D\n",
    "\n",
    "def pairwise_distances_broadcast(X):\n",
    "    \"\"\"Compute pairwise distances using broadcasting.\"\"\"\n",
    "    # Shape: (n, 1, d) - (1, n, d) = (n, n, d)\n",
    "    diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n",
    "    return np.sqrt(np.sum(diff**2, axis=-1))\n",
    "\n",
    "def pairwise_distances_einsum(X):\n",
    "    \"\"\"Compute pairwise distances using einsum.\"\"\"\n",
    "    # D[i,j] = ||X[i] - X[j]||² = ||X[i]||² + ||X[j]||² - 2*X[i]·X[j]\n",
    "    norms_sq = np.sum(X**2, axis=1)\n",
    "    dot_products = np.einsum('ik,jk->ij', X, X)\n",
    "    D_sq = norms_sq[:, np.newaxis] + norms_sq[np.newaxis, :] - 2 * dot_products\n",
    "    D_sq = np.maximum(D_sq, 0)  # Handle numerical errors\n",
    "    return np.sqrt(D_sq)\n",
    "\n",
    "# Benchmark\n",
    "n = 500\n",
    "X = np.random.randn(n, 3)\n",
    "\n",
    "print(f\"Pairwise distances for {n} points:\")\n",
    "\n",
    "stats = simple_timer(pairwise_distances_loop, X, n_runs=3)\n",
    "print(f\"  Loop:      {stats['mean']*1e3:8.2f} ms\")\n",
    "\n",
    "stats = simple_timer(pairwise_distances_broadcast, X, n_runs=10)\n",
    "print(f\"  Broadcast: {stats['mean']*1e3:8.2f} ms\")\n",
    "\n",
    "stats = simple_timer(pairwise_distances_einsum, X, n_runs=10)\n",
    "print(f\"  Einsum:    {stats['mean']*1e3:8.2f} ms\")\n",
    "\n",
    "# Verify results match\n",
    "D1 = pairwise_distances_loop(X)\n",
    "D2 = pairwise_distances_broadcast(X)\n",
    "D3 = pairwise_distances_einsum(X)\n",
    "print(f\"\\nMax difference: {max(np.max(np.abs(D1-D2)), np.max(np.abs(D1-D3))):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Kalman filter - vectorized version\n",
    "\n",
    "def batch_kf_predict_loop(x_batch, P_batch, F, Q):\n",
    "    \"\"\"Predict step using loop.\"\"\"\n",
    "    n_batch = len(x_batch)\n",
    "    x_pred = np.zeros_like(x_batch)\n",
    "    P_pred = np.zeros_like(P_batch)\n",
    "    \n",
    "    for i in range(n_batch):\n",
    "        x_pred[i] = F @ x_batch[i]\n",
    "        P_pred[i] = F @ P_batch[i] @ F.T + Q\n",
    "    \n",
    "    return x_pred, P_pred\n",
    "\n",
    "def batch_kf_predict_vectorized(x_batch, P_batch, F, Q):\n",
    "    \"\"\"Predict step using vectorized operations.\"\"\"\n",
    "    # x_pred[i] = F @ x_batch[i] -> use einsum\n",
    "    x_pred = np.einsum('ij,bj->bi', F, x_batch)\n",
    "    \n",
    "    # P_pred[i] = F @ P_batch[i] @ F.T + Q\n",
    "    FP = np.einsum('ij,bjk->bik', F, P_batch)  # F @ P for each batch\n",
    "    FPFt = np.einsum('bij,kj->bik', FP, F)     # ... @ F.T\n",
    "    P_pred = FPFt + Q\n",
    "    \n",
    "    return x_pred, P_pred\n",
    "\n",
    "# Benchmark\n",
    "n_batch = 1000\n",
    "state_dim = 6\n",
    "\n",
    "x_batch = np.random.randn(n_batch, state_dim)\n",
    "P_batch = np.tile(np.eye(state_dim), (n_batch, 1, 1))\n",
    "F = np.random.randn(state_dim, state_dim)\n",
    "Q = np.eye(state_dim) * 0.1\n",
    "\n",
    "print(f\"Batch KF predict ({n_batch} tracks, {state_dim}D state):\")\n",
    "\n",
    "stats = simple_timer(batch_kf_predict_loop, x_batch, P_batch, F, Q, n_runs=10)\n",
    "print(f\"  Loop:       {stats['mean']*1e3:8.2f} ms\")\n",
    "\n",
    "stats = simple_timer(batch_kf_predict_vectorized, x_batch, P_batch, F, Q, n_runs=10)\n",
    "print(f\"  Vectorized: {stats['mean']*1e3:8.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Caching Strategies\n",
    "\n",
    "Avoid recomputing expensive results that are used multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Spherical harmonic coefficients\n",
    "\n",
    "def compute_legendre_uncached(n_max, theta):\n",
    "    \"\"\"Compute associated Legendre polynomials without caching.\"\"\"\n",
    "    x = np.cos(theta)\n",
    "    P = np.zeros((n_max + 1, n_max + 1))\n",
    "    \n",
    "    P[0, 0] = 1.0\n",
    "    if n_max > 0:\n",
    "        P[1, 0] = x\n",
    "        P[1, 1] = -np.sin(theta)\n",
    "    \n",
    "    for n in range(2, n_max + 1):\n",
    "        for m in range(n + 1):\n",
    "            if m == n:\n",
    "                P[n, m] = -(2*n - 1) * np.sin(theta) * P[n-1, m-1]\n",
    "            elif m == n - 1:\n",
    "                P[n, m] = (2*n - 1) * x * P[n-1, m]\n",
    "            else:\n",
    "                P[n, m] = ((2*n - 1) * x * P[n-1, m] - (n + m - 1) * P[n-2, m]) / (n - m)\n",
    "    \n",
    "    return P\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def compute_legendre_cached(n_max, theta_index):\n",
    "    \"\"\"Compute associated Legendre polynomials with caching.\n",
    "    \n",
    "    Note: Using theta_index (discretized) for hashability.\n",
    "    \"\"\"\n",
    "    theta = theta_index * 0.01  # Convert index back to angle\n",
    "    return compute_legendre_uncached(n_max, theta)\n",
    "\n",
    "# Simulate repeated evaluation at same locations (common in tracking)\n",
    "n_max = 20\n",
    "n_evals = 1000\n",
    "n_unique_locations = 50  # Many evaluations at same locations\n",
    "\n",
    "# Random angles, but with repetition\n",
    "theta_unique = np.random.rand(n_unique_locations) * np.pi\n",
    "theta_indices = np.random.randint(0, n_unique_locations, n_evals)\n",
    "\n",
    "# Uncached\n",
    "start = time.time()\n",
    "for i in range(n_evals):\n",
    "    _ = compute_legendre_uncached(n_max, theta_unique[theta_indices[i]])\n",
    "uncached_time = time.time() - start\n",
    "\n",
    "# Cached (clear cache first)\n",
    "compute_legendre_cached.cache_clear()\n",
    "start = time.time()\n",
    "for i in range(n_evals):\n",
    "    # Convert theta to discrete index for caching\n",
    "    theta_idx = int(theta_unique[theta_indices[i]] * 100)\n",
    "    _ = compute_legendre_cached(n_max, theta_idx)\n",
    "cached_time = time.time() - start\n",
    "\n",
    "print(f\"Legendre polynomials (n_max={n_max}, {n_evals} evaluations):\")\n",
    "print(f\"  Uncached: {uncached_time*1e3:.2f} ms\")\n",
    "print(f\"  Cached:   {cached_time*1e3:.2f} ms\")\n",
    "print(f\"  Speedup:  {uncached_time/cached_time:.1f}x\")\n",
    "print(f\"  Cache hits: {compute_legendre_cached.cache_info().hits}\")\n",
    "print(f\"  Cache misses: {compute_legendre_cached.cache_info().misses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Memory Optimization\n",
    "\n",
    "Reducing memory allocations can significantly improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocation vs. dynamic allocation\n",
    "\n",
    "def simulate_with_append(n_steps):\n",
    "    \"\"\"Simulate trajectory using list append.\"\"\"\n",
    "    trajectory = []\n",
    "    x = np.zeros(4)\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        x = x + np.random.randn(4) * 0.1\n",
    "        trajectory.append(x.copy())\n",
    "    \n",
    "    return np.array(trajectory)\n",
    "\n",
    "def simulate_with_prealloc(n_steps):\n",
    "    \"\"\"Simulate trajectory with pre-allocated array.\"\"\"\n",
    "    trajectory = np.zeros((n_steps, 4))\n",
    "    x = np.zeros(4)\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        x = x + np.random.randn(4) * 0.1\n",
    "        trajectory[i] = x\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "# Benchmark\n",
    "n_steps = 10000\n",
    "\n",
    "stats1 = simple_timer(simulate_with_append, n_steps, n_runs=20)\n",
    "stats2 = simple_timer(simulate_with_prealloc, n_steps, n_runs=20)\n",
    "\n",
    "print(f\"Trajectory simulation ({n_steps} steps):\")\n",
    "print(f\"  List append:    {stats1['mean']*1e3:.2f} ms\")\n",
    "print(f\"  Pre-allocated:  {stats2['mean']*1e3:.2f} ms\")\n",
    "print(f\"  Speedup:        {stats1['mean']/stats2['mean']:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place operations\n",
    "\n",
    "def update_with_copy(x, dx):\n",
    "    \"\"\"Update using copy.\"\"\"\n",
    "    return x + dx\n",
    "\n",
    "def update_in_place(x, dx):\n",
    "    \"\"\"Update in place.\"\"\"\n",
    "    x += dx\n",
    "    return x\n",
    "\n",
    "# Benchmark with many iterations\n",
    "n_iter = 100000\n",
    "x = np.zeros(100)\n",
    "dx = np.random.randn(100) * 0.001\n",
    "\n",
    "# With copy\n",
    "x_copy = x.copy()\n",
    "start = time.time()\n",
    "for _ in range(n_iter):\n",
    "    x_copy = update_with_copy(x_copy, dx)\n",
    "copy_time = time.time() - start\n",
    "\n",
    "# In place\n",
    "x_inplace = x.copy()\n",
    "start = time.time()\n",
    "for _ in range(n_iter):\n",
    "    update_in_place(x_inplace, dx)\n",
    "inplace_time = time.time() - start\n",
    "\n",
    "print(f\"Update operations ({n_iter} iterations):\")\n",
    "print(f\"  With copy: {copy_time*1e3:.2f} ms\")\n",
    "print(f\"  In place:  {inplace_time*1e3:.2f} ms\")\n",
    "print(f\"  Speedup:   {copy_time/inplace_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Benchmarking Best Practices\n",
    "\n",
    "Guidelines for reliable performance measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliable_benchmark(func, *args, n_warmup=5, n_runs=50, **kwargs):\n",
    "    \"\"\"\n",
    "    Perform a reliable benchmark with proper warmup and statistics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Function to benchmark.\n",
    "    n_warmup : int\n",
    "        Number of warmup runs.\n",
    "    n_runs : int\n",
    "        Number of measurement runs.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Benchmark results with statistics.\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    \n",
    "    # Disable garbage collection during timing\n",
    "    gc_was_enabled = gc.isenabled()\n",
    "    gc.disable()\n",
    "    \n",
    "    try:\n",
    "        # Warmup\n",
    "        for _ in range(n_warmup):\n",
    "            func(*args, **kwargs)\n",
    "        \n",
    "        # Measurement\n",
    "        times = []\n",
    "        for _ in range(n_runs):\n",
    "            start = time.perf_counter_ns()\n",
    "            result = func(*args, **kwargs)\n",
    "            end = time.perf_counter_ns()\n",
    "            times.append((end - start) / 1e6)  # Convert to ms\n",
    "        \n",
    "    finally:\n",
    "        if gc_was_enabled:\n",
    "            gc.enable()\n",
    "    \n",
    "    times = np.array(times)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'median': np.median(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "        'p25': np.percentile(times, 25),\n",
    "        'p75': np.percentile(times, 75),\n",
    "        'n_runs': n_runs,\n",
    "        'times': times\n",
    "    }\n",
    "\n",
    "def print_benchmark_results(name, results):\n",
    "    \"\"\"Print formatted benchmark results.\"\"\"\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Mean:   {results['mean']:.3f} ms (±{results['std']:.3f})\")\n",
    "    print(f\"  Median: {results['median']:.3f} ms\")\n",
    "    print(f\"  Range:  [{results['min']:.3f}, {results['max']:.3f}] ms\")\n",
    "    print(f\"  IQR:    [{results['p25']:.3f}, {results['p75']:.3f}] ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive benchmark\n",
    "print(\"Comprehensive Benchmark Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Matrix operations\n",
    "n = 500\n",
    "A = np.random.randn(n, n)\n",
    "B = np.random.randn(n, n)\n",
    "\n",
    "results = reliable_benchmark(np.dot, A, B)\n",
    "print_benchmark_results(f\"Matrix multiply ({n}x{n})\", results)\n",
    "\n",
    "print()\n",
    "\n",
    "# Matrix inversion\n",
    "results = reliable_benchmark(np.linalg.inv, A)\n",
    "print_benchmark_results(f\"Matrix inversion ({n}x{n})\", results)\n",
    "\n",
    "print()\n",
    "\n",
    "# Hungarian assignment\n",
    "m = 100\n",
    "cost = np.random.rand(m, m) * 100\n",
    "results = reliable_benchmark(hungarian_assignment, cost)\n",
    "print_benchmark_results(f\"Hungarian assignment ({m}x{m})\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize benchmark distribution\n# Run multiple sizes\nsizes = [100, 200, 300, 400, 500]\nmeans = []\nstds = []\n\nfor n in sizes:\n    A = np.random.randn(n, n)\n    B = np.random.randn(n, n)\n    results = reliable_benchmark(np.dot, A, B, n_runs=50)\n    means.append(results['mean'])\n    stds.append(results['std'])\n\nmeans = np.array(means)\nstds = np.array(stds)\n\nfig = go.Figure()\n\n# Error bars with shaded region\nfig.add_trace(\n    go.Scatter(x=sizes, y=means + stds, mode='lines',\n               line=dict(width=0), showlegend=False, hoverinfo='skip')\n)\nfig.add_trace(\n    go.Scatter(x=sizes, y=means - stds, mode='lines',\n               fill='tonexty', fillcolor='rgba(0, 212, 255, 0.3)',\n               line=dict(width=0), name='±1σ')\n)\nfig.add_trace(\n    go.Scatter(x=sizes, y=means, mode='lines+markers',\n               name='Mean time', line=dict(color='#00d4ff', width=2),\n               marker=dict(size=10), error_y=dict(type='data', array=stds,\n                                                   visible=True, color='#00d4ff'))\n)\n\n# O(n³) reference\nn3_fit = means[0] * (np.array(sizes) / sizes[0])**3\nfig.add_trace(\n    go.Scatter(x=sizes, y=n3_fit, mode='lines',\n               name='O(n³) reference', line=dict(color='#ff4757', width=1.5, dash='dash'))\n)\n\nfig.update_layout(\n    template=dark_template,\n    title='Matrix Multiplication Benchmark',\n    xaxis_title='Matrix Size',\n    yaxis_title='Time (ms)',\n    height=450,\n)\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key optimization strategies:\n",
    "\n",
    "1. **Profile first** - Don't optimize blindly\n",
    "2. **Vectorize** - Replace loops with NumPy operations\n",
    "3. **Use Numba** - JIT compile hot spots\n",
    "4. **Cache results** - Avoid redundant computation\n",
    "5. **Pre-allocate** - Reduce memory allocation overhead\n",
    "6. **In-place operations** - Avoid unnecessary copies\n",
    "\n",
    "### Optimization Checklist\n",
    "\n",
    "| Check | Description |\n",
    "|-------|-------------|\n",
    "| Profile | Identify actual bottlenecks |\n",
    "| Vectorize | Replace Python loops with NumPy |\n",
    "| Numba | JIT compile remaining loops |\n",
    "| Cache | Memoize expensive pure functions |\n",
    "| Pre-allocate | Use np.zeros instead of append |\n",
    "| In-place | Use += instead of x = x + |\n",
    "| Data types | Use float32 if precision allows |\n",
    "| Parallel | Use Numba prange or multiprocessing |\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Profile a complete multi-target tracking pipeline and identify bottlenecks\n",
    "2. Implement a Numba-accelerated particle filter resampling algorithm\n",
    "3. Create a caching decorator that tracks cache hit rates\n",
    "4. Optimize the JPDA algorithm for 1000+ tracks\n",
    "\n",
    "## References\n",
    "\n",
    "1. VanderPlas, J. (2016). *Python Data Science Handbook*.\n",
    "2. Numba Documentation: https://numba.pydata.org/\n",
    "3. NumPy Performance Tips: https://numpy.org/doc/stable/user/quickstart.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
