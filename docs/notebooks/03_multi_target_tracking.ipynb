{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Multi-Target Tracking: Data Association and Tracking\n\nThis notebook covers multi-target tracking techniques using the Tracker Component Library:\n\n1. **Data Association Problem** - Matching measurements to tracks\n2. **Global Nearest Neighbor (GNN)** - Simple greedy association\n3. **Joint Probabilistic Data Association (JPDA)** - Soft association with probabilities\n4. **Multiple Hypothesis Tracking (MHT)** - Deferred decision tracking\n5. **Track Management** - Initiation, confirmation, and deletion\n\n## Prerequisites\n\n```bash\npip install nrl-tracker plotly numpy scipy\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom scipy.stats import chi2\n\nfrom pytcl.dynamic_estimation import kf_predict, kf_update\nfrom pytcl.assignment_algorithms import (\n    hungarian_assignment,\n    jpda, jpda_update,\n    compute_likelihood_matrix, jpda_probabilities,\n)\nfrom pytcl.performance_evaluation import ospa\n\nnp.random.seed(42)\n\n# Plotly dark theme template\ndark_template = go.layout.Template()\ndark_template.layout = go.Layout(\n    paper_bgcolor='#0d1117',\n    plot_bgcolor='#0d1117',\n    font=dict(color='#e6edf3'),\n    xaxis=dict(gridcolor='#30363d', zerolinecolor='#30363d'),\n    yaxis=dict(gridcolor='#30363d', zerolinecolor='#30363d'),\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Data Association Problem\n",
    "\n",
    "In multi-target tracking, we must determine which measurements correspond to which tracks. This is challenging due to:\n",
    "\n",
    "- **Clutter**: False alarms that don't correspond to any target\n",
    "- **Missed detections**: Targets that aren't detected\n",
    "- **Close targets**: Ambiguous associations when targets are near each other\n",
    "\n",
    "### Scenario Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 1.0  # Time step\n",
    "n_steps = 50\n",
    "n_targets = 3\n",
    "\n",
    "# Detection parameters\n",
    "P_detection = 0.9  # Probability of detection\n",
    "lambda_clutter = 2  # Average number of clutter points per scan\n",
    "surveillance_area = [[-50, 50], [-50, 50]]  # x and y bounds\n",
    "\n",
    "# Motion model: constant velocity\n",
    "F = np.array([\n",
    "    [1, dt, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, dt],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "q = 0.1  # Process noise\n",
    "Q = q * np.array([\n",
    "    [dt**3/3, dt**2/2, 0, 0],\n",
    "    [dt**2/2, dt, 0, 0],\n",
    "    [0, 0, dt**3/3, dt**2/2],\n",
    "    [0, 0, dt**2/2, dt]\n",
    "])\n",
    "\n",
    "# Measurement model: position only\n",
    "H = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "R = np.eye(2) * 2.0  # Measurement noise covariance\n",
    "\n",
    "print(f\"Simulating {n_targets} targets over {n_steps} time steps\")\n",
    "print(f\"P_d = {P_detection}, Î»_clutter = {lambda_clutter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate target trajectories\ninitial_states = [\n    np.array([-40, 1.5, -30, 0.5]),   # Target 1: moving right-up\n    np.array([30, -1.0, -20, 1.0]),   # Target 2: moving left-up\n    np.array([0, 0.2, 40, -1.2]),     # Target 3: moving right-down\n]\n\ntrue_tracks = [[] for _ in range(n_targets)]\nstates = [s.copy() for s in initial_states]\n\nfor k in range(n_steps):\n    for i in range(n_targets):\n        true_tracks[i].append(states[i].copy())\n        states[i] = F @ states[i] + np.random.multivariate_normal(np.zeros(4), Q)\n\ntrue_tracks = [np.array(t) for t in true_tracks]\n\n# Visualize true trajectories\ncolors = ['#00d4ff', '#ff4757', '#00ff88']\n\nfig = go.Figure()\n\nfor i, track in enumerate(true_tracks):\n    # Trajectory line\n    fig.add_trace(\n        go.Scatter(x=track[:, 0], y=track[:, 2], mode='lines',\n                   name=f'Target {i+1}', line=dict(color=colors[i], width=2))\n    )\n    # Start marker\n    fig.add_trace(\n        go.Scatter(x=[track[0, 0]], y=[track[0, 2]], mode='markers',\n                   marker=dict(color=colors[i], size=12, symbol='circle'),\n                   name=f'Start {i+1}', showlegend=False)\n    )\n    # End marker\n    fig.add_trace(\n        go.Scatter(x=[track[-1, 0]], y=[track[-1, 2]], mode='markers',\n                   marker=dict(color=colors[i], size=12, symbol='square'),\n                   name=f'End {i+1}', showlegend=False)\n    )\n\nfig.update_layout(\n    template=dark_template,\n    title='True Target Trajectories',\n    xaxis_title='X position',\n    yaxis_title='Y position',\n    height=500,\n    xaxis=dict(range=surveillance_area[0], scaleanchor='y', scaleratio=1),\n    yaxis=dict(range=surveillance_area[1]),\n)\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate measurements with missed detections and clutter\n",
    "all_measurements = []\n",
    "detection_flags = []  # Track which targets were detected\n",
    "\n",
    "for k in range(n_steps):\n",
    "    scan_measurements = []\n",
    "    scan_detections = []\n",
    "    \n",
    "    # Target-originated measurements\n",
    "    for i, track in enumerate(true_tracks):\n",
    "        detected = np.random.random() < P_detection\n",
    "        scan_detections.append(detected)\n",
    "        \n",
    "        if detected:\n",
    "            true_pos = H @ track[k]\n",
    "            z = true_pos + np.random.multivariate_normal(np.zeros(2), R)\n",
    "            scan_measurements.append(z)\n",
    "    \n",
    "    # Clutter\n",
    "    n_clutter = np.random.poisson(lambda_clutter)\n",
    "    for _ in range(n_clutter):\n",
    "        x_clut = np.random.uniform(*surveillance_area[0])\n",
    "        y_clut = np.random.uniform(*surveillance_area[1])\n",
    "        scan_measurements.append(np.array([x_clut, y_clut]))\n",
    "    \n",
    "    # Shuffle to remove ordering information\n",
    "    if scan_measurements:\n",
    "        perm = np.random.permutation(len(scan_measurements))\n",
    "        scan_measurements = [scan_measurements[j] for j in perm]\n",
    "    \n",
    "    all_measurements.append(scan_measurements)\n",
    "    detection_flags.append(scan_detections)\n",
    "\n",
    "# Statistics\n",
    "total_detections = sum(sum(d) for d in detection_flags)\n",
    "total_clutter = sum(len(m) for m in all_measurements) - total_detections\n",
    "print(f\"Total detections: {total_detections} / {n_steps * n_targets} ({100*total_detections/(n_steps*n_targets):.1f}%)\")\n",
    "print(f\"Total clutter: {total_clutter}\")\n",
    "print(f\"Average measurements per scan: {np.mean([len(m) for m in all_measurements]):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Nearest Neighbor (GNN)\n",
    "\n",
    "The simplest association method: assign each track to its nearest measurement using the Hungarian algorithm. Drawbacks:\n",
    "- Hard decisions can lead to track swaps\n",
    "- Doesn't handle ambiguity well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track:\n",
    "    \"\"\"Simple track class for demonstration.\"\"\"\n",
    "    def __init__(self, x0, P0, track_id):\n",
    "        self.x = x0.copy()\n",
    "        self.P = P0.copy()\n",
    "        self.id = track_id\n",
    "        self.history = [x0.copy()]\n",
    "        self.missed_count = 0\n",
    "        \n",
    "    def predict(self, F, Q):\n",
    "        pred = kf_predict(self.x, self.P, F, Q)\n",
    "        self.x, self.P = pred.x, pred.P\n",
    "        \n",
    "    def update(self, z, H, R):\n",
    "        upd = kf_update(self.x, self.P, z, H, R)\n",
    "        self.x, self.P = upd.x, upd.P\n",
    "        self.history.append(self.x.copy())\n",
    "        self.missed_count = 0\n",
    "        \n",
    "    def coast(self):\n",
    "        self.history.append(self.x.copy())\n",
    "        self.missed_count += 1\n",
    "\n",
    "def mahalanobis_distance(track, z, H, R):\n",
    "    \"\"\"Compute Mahalanobis distance from track to measurement.\"\"\"\n",
    "    z_pred = H @ track.x\n",
    "    S = H @ track.P @ H.T + R\n",
    "    residual = z - z_pred\n",
    "    d2 = residual @ np.linalg.solve(S, residual)\n",
    "    return d2\n",
    "\n",
    "def gnn_associate(tracks, measurements, H, R, gate_threshold=9.21):  # chi2(2, 0.99)\n",
    "    \"\"\"Global Nearest Neighbor association.\"\"\"\n",
    "    n_tracks = len(tracks)\n",
    "    n_meas = len(measurements)\n",
    "    \n",
    "    if n_tracks == 0 or n_meas == 0:\n",
    "        return {}, list(range(n_meas))\n",
    "    \n",
    "    # Build cost matrix (Mahalanobis distances)\n",
    "    cost_matrix = np.full((n_tracks, n_meas), np.inf)\n",
    "    for i, track in enumerate(tracks):\n",
    "        for j, z in enumerate(measurements):\n",
    "            d2 = mahalanobis_distance(track, z, H, R)\n",
    "            if d2 < gate_threshold:\n",
    "                cost_matrix[i, j] = d2\n",
    "    \n",
    "    # Hungarian algorithm\n",
    "    row_ind, col_ind, cost = hungarian_assignment(cost_matrix)\n",
    "    \n",
    "    # Build associations\n",
    "    associations = {}\n",
    "    assigned_meas = set()\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if cost_matrix[i, j] < gate_threshold:\n",
    "            associations[i] = j\n",
    "            assigned_meas.add(j)\n",
    "    \n",
    "    unassigned = [j for j in range(n_meas) if j not in assigned_meas]\n",
    "    return associations, unassigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GNN tracker\n",
    "# Initialize with first measurements (simplified - assume first 3 are targets)\n",
    "P0 = np.diag([R[0,0], 1.0, R[1,1], 1.0])  # Initial covariance\n",
    "\n",
    "gnn_tracks = []\n",
    "for i, state in enumerate(initial_states):\n",
    "    # Initialize near true state (cheating slightly for demo)\n",
    "    x0 = state + np.random.multivariate_normal(np.zeros(4), P0 * 0.1)\n",
    "    gnn_tracks.append(Track(x0, P0.copy(), i))\n",
    "\n",
    "# Process all scans\n",
    "for k, measurements in enumerate(all_measurements):\n",
    "    # Predict\n",
    "    for track in gnn_tracks:\n",
    "        track.predict(F, Q)\n",
    "    \n",
    "    # Associate\n",
    "    associations, unassigned = gnn_associate(gnn_tracks, measurements, H, R)\n",
    "    \n",
    "    # Update associated tracks\n",
    "    for track_idx, meas_idx in associations.items():\n",
    "        gnn_tracks[track_idx].update(measurements[meas_idx], H, R)\n",
    "    \n",
    "    # Coast unassociated tracks\n",
    "    for i, track in enumerate(gnn_tracks):\n",
    "        if i not in associations:\n",
    "            track.coast()\n",
    "\n",
    "print(f\"GNN tracking complete. {len(gnn_tracks)} tracks maintained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize GNN results\nfig = go.Figure()\n\n# True trajectories (semi-transparent)\nfor i, track in enumerate(true_tracks):\n    fig.add_trace(\n        go.Scatter(x=track[:, 0], y=track[:, 2], mode='lines',\n                   name=f'True {i+1}', line=dict(color=colors[i], width=2),\n                   opacity=0.5)\n    )\n\n# GNN estimates (dashed)\nfor i, track in enumerate(gnn_tracks):\n    history = np.array(track.history)\n    fig.add_trace(\n        go.Scatter(x=history[:, 0], y=history[:, 2], mode='lines',\n                   name=f'GNN Track {i+1}', line=dict(color=colors[i], width=2, dash='dash'))\n    )\n\n# Measurements from last scan\nlast_meas = all_measurements[-1]\nfig.add_trace(\n    go.Scatter(x=[z[0] for z in last_meas], y=[z[1] for z in last_meas], mode='markers',\n               name='Last scan', marker=dict(color='gray', size=6, opacity=0.5))\n)\n\nfig.update_layout(\n    template=dark_template,\n    title='GNN Multi-Target Tracking',\n    xaxis_title='X position',\n    yaxis_title='Y position',\n    height=550,\n    xaxis=dict(scaleanchor='y', scaleratio=1),\n)\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Joint Probabilistic Data Association (JPDA)\n",
    "\n",
    "JPDA computes the probability of each measurement-to-track association and uses a weighted combination for the update:\n",
    "\n",
    "$$\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K \\sum_{j=0}^{m} \\beta_j (z_j - H\\hat{x}_{k|k-1})$$\n",
    "\n",
    "where $\\beta_j$ is the probability that measurement $j$ originated from the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run JPDA tracker\n",
    "jpda_tracks = []\n",
    "for i, state in enumerate(initial_states):\n",
    "    x0 = state + np.random.multivariate_normal(np.zeros(4), P0 * 0.1)\n",
    "    jpda_tracks.append(Track(x0, P0.copy(), i))\n",
    "\n",
    "# Clutter density\n",
    "area = (surveillance_area[0][1] - surveillance_area[0][0]) * \\\n",
    "       (surveillance_area[1][1] - surveillance_area[1][0])\n",
    "clutter_density = lambda_clutter / area\n",
    "\n",
    "for k, measurements in enumerate(all_measurements):\n",
    "    # Predict\n",
    "    for track in jpda_tracks:\n",
    "        track.predict(F, Q)\n",
    "    \n",
    "    if len(measurements) == 0:\n",
    "        for track in jpda_tracks:\n",
    "            track.coast()\n",
    "        continue\n",
    "    \n",
    "    # Get track states and covariances\n",
    "    states = [t.x for t in jpda_tracks]\n",
    "    covs = [t.P for t in jpda_tracks]\n",
    "    meas_array = np.array(measurements)\n",
    "    \n",
    "    # Compute likelihood matrix and association probabilities\n",
    "    L, gated = compute_likelihood_matrix(states, covs, meas_array, H, R)\n",
    "    beta = jpda_probabilities(L, gated, P_detection, clutter_density)\n",
    "    \n",
    "    # JPDA update for each track\n",
    "    for i, track in enumerate(jpda_tracks):\n",
    "        # Weighted innovation\n",
    "        z_pred = H @ track.x\n",
    "        S = H @ track.P @ H.T + R\n",
    "        K = track.P @ H.T @ np.linalg.inv(S)\n",
    "        \n",
    "        # Weighted sum of innovations\n",
    "        innovation = np.zeros(2)\n",
    "        for j in range(len(measurements)):\n",
    "            innovation += beta[i, j] * (measurements[j] - z_pred)\n",
    "        \n",
    "        # Update state\n",
    "        track.x = track.x + K @ innovation\n",
    "        \n",
    "        # Update covariance (spread of the means + innovation uncertainty)\n",
    "        P_c = (1 - sum(beta[i, :-1])) * track.P  # Coast term\n",
    "        P_u = (np.eye(4) - K @ H) @ track.P  # Update term\n",
    "        track.P = beta[i, -1] * track.P + (1 - beta[i, -1]) * P_u\n",
    "        \n",
    "        track.history.append(track.x.copy())\n",
    "        \n",
    "print(f\"JPDA tracking complete. {len(jpda_tracks)} tracks maintained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare GNN vs JPDA\nfig = make_subplots(rows=1, cols=2, subplot_titles=('GNN Tracking', 'JPDA Tracking'),\n                    horizontal_spacing=0.1)\n\ntracker_data = [('GNN', gnn_tracks), ('JPDA', jpda_tracks)]\n\nfor col, (tracker_name, tracks) in enumerate(tracker_data, 1):\n    # True trajectories\n    for i, track in enumerate(true_tracks):\n        fig.add_trace(\n            go.Scatter(x=track[:, 0], y=track[:, 2], mode='lines',\n                       name=f'True {i+1}' if col == 1 else None,\n                       line=dict(color=colors[i], width=2), opacity=0.4,\n                       showlegend=(col == 1)),\n            row=1, col=col\n        )\n    \n    # Tracker estimates\n    for i, track in enumerate(tracks):\n        history = np.array(track.history)\n        fig.add_trace(\n            go.Scatter(x=history[:, 0], y=history[:, 2], mode='lines',\n                       name=f'{tracker_name} {i+1}' if col == 1 else None,\n                       line=dict(color=colors[i], width=2, dash='dash'),\n                       showlegend=(col == 1)),\n            row=1, col=col\n        )\n\nfig.update_layout(\n    template=dark_template,\n    height=450,\n)\nfig.update_xaxes(title_text='X position', row=1, col=1)\nfig.update_xaxes(title_text='X position', row=1, col=2)\nfig.update_yaxes(title_text='Y position', row=1, col=1)\nfig.update_yaxes(title_text='Y position', row=1, col=2)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tracking errors\n",
    "def compute_position_rmse(tracker_tracks, true_tracks):\n",
    "    \"\"\"Compute RMSE for each track.\"\"\"\n",
    "    rmse = []\n",
    "    for i, (tracker, truth) in enumerate(zip(tracker_tracks, true_tracks)):\n",
    "        history = np.array(tracker.history)\n",
    "        # Align lengths\n",
    "        min_len = min(len(history), len(truth))\n",
    "        pos_error = np.sqrt((history[:min_len, 0] - truth[:min_len, 0])**2 + \n",
    "                            (history[:min_len, 2] - truth[:min_len, 2])**2)\n",
    "        rmse.append(np.sqrt(np.mean(pos_error**2)))\n",
    "    return rmse\n",
    "\n",
    "gnn_rmse = compute_position_rmse(gnn_tracks, true_tracks)\n",
    "jpda_rmse = compute_position_rmse(jpda_tracks, true_tracks)\n",
    "\n",
    "print(\"Position RMSE (m):\")\n",
    "print(f\"{'Track':<10} {'GNN':>10} {'JPDA':>10}\")\n",
    "print(\"-\" * 32)\n",
    "for i in range(n_targets):\n",
    "    print(f\"Target {i+1:<4} {gnn_rmse[i]:>10.3f} {jpda_rmse[i]:>10.3f}\")\n",
    "print(\"-\" * 32)\n",
    "print(f\"{'Average':<10} {np.mean(gnn_rmse):>10.3f} {np.mean(jpda_rmse):>10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Evaluation with OSPA\n",
    "\n",
    "The Optimal Subpattern Assignment (OSPA) metric provides a principled way to measure multi-target tracking performance:\n",
    "\n",
    "$$d_{OSPA}(X, Y) = \\left( \\frac{1}{n} \\left( \\min_{\\pi} \\sum_{i=1}^m d^p(x_i, y_{\\pi(i)}) + c^p(n-m) \\right) \\right)^{1/p}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute OSPA over time\ndef compute_ospa_sequence(tracker_tracks, true_tracks, c=10, p=2):\n    \"\"\"Compute OSPA at each time step.\"\"\"\n    ospa_values = []\n    \n    # Get minimum length\n    min_len = min(\n        min(len(t.history) for t in tracker_tracks),\n        min(len(t) for t in true_tracks)\n    )\n    \n    for k in range(min_len):\n        # Get positions at time k\n        est_pos = np.array([[t.history[k][0], t.history[k][2]] for t in tracker_tracks])\n        true_pos = np.array([[t[k, 0], t[k, 2]] for t in true_tracks])\n        \n        # Compute OSPA\n        ospa_val = ospa(est_pos, true_pos, c=c, p=p)\n        ospa_values.append(ospa_val)\n    \n    return np.array(ospa_values)\n\ngnn_ospa = compute_ospa_sequence(gnn_tracks, true_tracks)\njpda_ospa = compute_ospa_sequence(jpda_tracks, true_tracks)\n\nfig = go.Figure()\n\ntime = np.arange(len(gnn_ospa)) * dt\nfig.add_trace(\n    go.Scatter(x=time, y=gnn_ospa, mode='lines',\n               name=f'GNN (mean: {np.mean(gnn_ospa):.2f})',\n               line=dict(color='#00d4ff', width=2))\n)\nfig.add_trace(\n    go.Scatter(x=time, y=jpda_ospa, mode='lines',\n               name=f'JPDA (mean: {np.mean(jpda_ospa):.2f})',\n               line=dict(color='#ff4757', width=2))\n)\n\nfig.update_layout(\n    template=dark_template,\n    title='OSPA Metric Over Time',\n    xaxis_title='Time (s)',\n    yaxis_title='OSPA distance (m)',\n    height=400,\n)\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Pros | Cons |\n",
    "|--------|------|------|\n",
    "| **GNN** | Simple, fast | Hard decisions, track swaps |\n",
    "| **JPDA** | Soft associations, handles ambiguity | Higher complexity, maintains all associations |\n",
    "| **MHT** | Optimal, deferred decisions | Exponential complexity, requires pruning |\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Add track initiation and deletion logic to handle new targets\n",
    "2. Implement a crossing scenario where targets pass close to each other\n",
    "3. Compare performance with different clutter densities\n",
    "4. Implement basic MHT with hypothesis pruning\n",
    "\n",
    "## References\n",
    "\n",
    "1. Bar-Shalom, Y., & Li, X. R. (1995). *Multitarget-Multisensor Tracking*.\n",
    "2. Blackman, S. S., & Popoli, R. (1999). *Design and Analysis of Modern Tracking Systems*.\n",
    "3. Schuhmacher, D., et al. (2008). A consistent metric for performance evaluation of multi-object filters. *IEEE TSP*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}